{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline classifier for zebrafish classification\n",
    "\n",
    "The baseline classifier is a shallow convolutional network which serves as a comparisson for the transfer learning classifier performance later on. The model contains 4 convolutional and maxpooling layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from skimage.transform import resize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from itertools import islice\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "import tifffile\n",
    "from tqdm.auto import tqdm \n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "from utils import create_dataset\n",
    "# set manual seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the zebrafish data\n",
    "\n",
    "Download and unzip the training data (images and classes) into the subfolder `data`\n",
    "```\n",
    "wget https://zenodo.org/record/6651752/files/data.zip?download=1  -O data.zip\n",
    "unzip data.zip\n",
    "```\n",
    "\n",
    "Which should result in the following \n",
    "\n",
    "```\n",
    "data\n",
    "├── fish_part_labels\n",
    "│   ├── DAPT\n",
    "│   ├── her1;her7\n",
    "│   ├── tbx6_fss\n",
    "│   └── WT\n",
    "├── training\n",
    "│   ├── DAPT\n",
    "│   ├── her1;her7\n",
    "│   ├── tbx6_fss\n",
    "│   └── WT\n",
    "└── validation\n",
    "    ├── DAPT\n",
    "    ├── her1;her7\n",
    "    ├── tbx6_fss\n",
    "    └── WT\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot= Path('data')\n",
    "target_size = (450,900)\n",
    "epochs=50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the zebrafish data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = create_dataset(dataroot/\"training\",   target_size=target_size, batchsize=16, shuffle=True, augment=True)\n",
    "data_val   = create_dataset(dataroot/\"validation\", target_size=target_size, batchsize=16, shuffle=False, augment=False)\n",
    "\n",
    "print(data_train.class_name_to_id)\n",
    "print(data_train.class_id_to_name)\n",
    "\n",
    "# plot some example training and validation images\n",
    "n=5\n",
    "x,y = next(iter(data_train.data))\n",
    "plt.figure(figsize=(20,5))\n",
    "for i, (_x, _y) in enumerate(zip(x[:2*n],y[:2*n])):\n",
    "    plt.subplot(2,n, i+1)\n",
    "    plt.imshow(np.clip(_x, 0,1))\n",
    "    plt.title(f'Training image - class = {data_train.class_id_to_name[int(_y)]} ({int(_y)})')\n",
    "\n",
    "x,y = next(iter(data_val.data))\n",
    "plt.figure(figsize=(20,5))\n",
    "for i, (_x, _y) in enumerate(zip(x[:2*n],y[:2*n])):\n",
    "    plt.subplot(2,n, i+1)\n",
    "    plt.imshow(np.clip(_x, 0,1))\n",
    "    plt.title(f'validation image - class = {data_train.class_id_to_name[int(_y)]} ({int(_y)})')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building and compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(32,7,activation=\"relu\", strides=4, padding=\"same\", input_shape = x.shape[1:]))\n",
    "for _ in range(3):\n",
    "    model.add(tf.keras.layers.Conv2D(32,3,activation=\"relu\", strides=4, padding=\"same\"))\n",
    "model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(4,)) #from_logits = True so no need for softmax here\n",
    "\n",
    "model.summary()\n",
    "\n",
    "learning_rate = 0.0005\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "          loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "          metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "#preparing the weights for balanced training\n",
    "counts = Counter(data_train.labels)\n",
    "counts_mean = np.mean(tuple(counts.values()))\n",
    "class_weights = dict((k, np.sqrt(counts_mean/v)) for k,v in counts.items())\n",
    "print(f'class weights: {class_weights}')\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,patience=2, min_lr=0.00025, verbose = 1)\n",
    "\n",
    "checkpoint_folder = Path('checkpoints')\n",
    "checkpoint_folder.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "checkpoint_filepath = checkpoint_folder/\"baseline_classifier.h5\"\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model.fit(data_train.data.repeat(4),\n",
    "                epochs=epochs,\n",
    "                validation_data = data_val.data,\n",
    "                class_weight=class_weights, callbacks=[model_checkpoint_callback])\n",
    "np.save(checkpoint_folder/f\"baseline_classifier_lr_{learning_rate:.4f}_epochs_{epochs}.npy\",history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading best weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array(data_val.labels)\n",
    "y_pred = np.argmax(model.predict(data_val.data), -1)\n",
    "\n",
    "def calculate_confusion_matrix(y_true, y_pred):\n",
    "    classes = tuple(data_val.class_id_to_name[i] for i in range(4))\n",
    "    matrix = metrics.confusion_matrix(y_true, y_pred) #rows - true, columns - predicted\n",
    "    matrix = matrix/np.sum(matrix, axis=-1, keepdims=True)\n",
    "    \n",
    "    df_cm = pd.DataFrame(matrix, index=classes, columns=classes)\n",
    "    # plt.figure(figsize=(10,7))\n",
    "    sns.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}, fmt='1.3f')# font size\n",
    "    plt.ylabel(\"True class\")\n",
    "    plt.xlabel(\"Predicted class\") \n",
    "    plt.show()\n",
    "    accuracy = np.sum(np.diag(matrix))/np.sum(matrix)\n",
    "    print(f'Accuracy: {accuracy:.4f}') \n",
    "    return accuracy\n",
    "\n",
    "accuracy = calculate_confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply the model to new images from a different microscope (`kings` subset)\n",
    "\n",
    "Put the `kings` images (in bmp format) in the subfolder `data/kings`, resulting in \n",
    "\n",
    "```\n",
    "data\n",
    "├── fish_part_labels\n",
    "│   ├── DAPT\n",
    "│   ├── her1;her7\n",
    "│   ├── tbx6_fss\n",
    "│   └── WT\n",
    "├── kings\n",
    "│   ├── DAPT\n",
    "│   └── WT\n",
    "├── training\n",
    "│   ├── DAPT\n",
    "│   ├── her1;her7\n",
    "│   ├── tbx6_fss\n",
    "│   └── WT\n",
    "└── validation\n",
    "    ├── DAPT\n",
    "    ├── her1;her7\n",
    "    ├── tbx6_fss\n",
    "    └── WT\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = create_dataset(dataroot/'kings', augment=False, shuffle=False, target_size=target_size)\n",
    "\n",
    "x,y = next(iter(data_new.data))\n",
    "plt.figure(figsize=(20,5))\n",
    "for i, (_x, _y) in enumerate(zip(x[:2*n],y[:2*n])):\n",
    "    plt.subplot(2,n, i+1)\n",
    "    plt.imshow(np.clip(_x, 0,1))\n",
    "    plt.title(f'New image - class = {data_train.class_id_to_name[int(_y)]} ({int(_y)})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_true = np.array(tuple(data_new.class_id_to_name[c] for c in data_new.labels))\n",
    "y_pred = np.array(tuple(data_train.class_id_to_name[c] for c in np.argmax(model.predict(data_new.data), -1)))\n",
    "\n",
    "accuracy = np.mean(y_true==y_pred)\n",
    "print(f'Accuracy: {accuracy:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "save_folder = Path(\"test_predictions\") \n",
    "save_folder.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "for i, (x, fname, y1, y2) in enumerate(zip(data_new.images, data_new.filenames, y_true, y_pred)):\n",
    "    if i%4==0:\n",
    "        plt.figure(figsize=(20,4))\n",
    "    ax = plt.subplot(1,4,i%4+1)\n",
    "    ax.imshow(x)\n",
    "    correct = y1==y2\n",
    "    ax.set_title(f'{\"correct\" if correct else \"wrong\"} ({y1} -> {y2})', fontsize=10)\n",
    "    ax.title.set_color('green' if correct else 'red')\n",
    "    ax.axis('off')\n",
    "    plt.savefig(save_folder/f'{Path(fname).name}_{y1}_{\"correct\" if correct else \"wrong\"}_as_{y2}.jpg', dpi = 200, transparent=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
