{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning classifier for zebrafish classification\n",
    "\n",
    "This notebook is used for training of transfer learning, MobileNetV2-based classifier of zebrafish embryo mutants. The training and evaluation of the classifier is followed by Class activation mapping (CAM) analysis which points to the predictive feature of the zebrafish embryo images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from skimage.transform import resize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tifffile\n",
    "from tqdm.auto import tqdm \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from itertools import islice\n",
    "from sklearn import metrics\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "from utils import create_dataset\n",
    "# set manual seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the zebrafish data\n",
    "\n",
    "Download and unzip the training data (images and classes) into the subfolder `data`\n",
    "```\n",
    "wget https://zenodo.org/record/6651752/files/data.zip?download=1  -O data.zip\n",
    "unzip data.zip\n",
    "```\n",
    "\n",
    "Which should result in the following \n",
    "\n",
    "```\n",
    "data\n",
    "├── fish_part_labels\n",
    "│   ├── DAPT\n",
    "│   ├── her1;her7\n",
    "│   ├── tbx6_fss\n",
    "│   └── WT\n",
    "├── training\n",
    "│   ├── DAPT\n",
    "│   ├── her1;her7\n",
    "│   ├── tbx6_fss\n",
    "│   └── WT\n",
    "└── validation\n",
    "    ├── DAPT\n",
    "    ├── her1;her7\n",
    "    ├── tbx6_fss\n",
    "    └── WT\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot= Path('data')\n",
    "target_size = (450,900)\n",
    "\n",
    "epochs  = 100\n",
    "seed=1\n",
    "n_tiles = 1 # splits images in n_tiles along every axis (to asses how much context matters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the zebrafish data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_train = create_dataset(dataroot/\"training\",   target_size=target_size, batchsize=16, shuffle=True, seed=seed, validation_split=0.1, subset='training', augment=True, n_tiles=n_tiles)\n",
    "data_val   = create_dataset(dataroot/\"training\",   target_size=target_size, batchsize=16, shuffle=True, seed=seed, validation_split=0.1, subset='validation', augment=False, n_tiles=n_tiles)\n",
    "\n",
    "print(data_train.class_name_to_id)\n",
    "print(data_train.class_id_to_name)\n",
    "\n",
    "if not len(data_train.counts)==4:\n",
    "    raise ValueError('Less than 4 classes sampled for data_train, try a different seed!')\n",
    "\n",
    "if not len(data_val.counts)==4:\n",
    "    raise ValueError('Less than 4 classes sampled for data_val, try a different seed!')\n",
    "    \n",
    "    \n",
    "# plot some example training and validation images\n",
    "n=5\n",
    "\n",
    "x,y = next(iter(data_train.data))\n",
    "plt.figure(figsize=(20,6))\n",
    "for i, (_x, _y) in enumerate(zip(x[:2*n],y[:2*n])):\n",
    "    plt.subplot(2,n, i+1)\n",
    "    plt.imshow(np.clip(_x, 0,1))\n",
    "    plt.title(f'Training - class = {data_train.class_id_to_name[int(_y)]} ({int(_y)})')\n",
    "\n",
    "x,y = next(iter(data_val.data))\n",
    "plt.figure(figsize=(20,6))\n",
    "for i, (_x, _y) in enumerate(zip(x[:2*n],y[:2*n])):\n",
    "    plt.subplot(2,n, i+1)\n",
    "    plt.imshow(np.clip(_x, 0,1))\n",
    "    plt.title(f'Validation - class = {data_train.class_id_to_name[int(_y)]} ({int(_y)})')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building and compiling transfer learning classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inp = tf.keras.Input(shape=tuple(s//n_tiles for s in target_size)+(3,))\n",
    "model_pretrained = tf.keras.applications.MobileNetV2(input_shape = tuple(s//n_tiles for s in target_size)+(3,), \n",
    "                                       include_top=False, weights='imagenet')\n",
    "model_pretrained.trainable = False #freeze the weights\n",
    "out = model_pretrained(inp, training=False)\n",
    "out = tf.keras.layers.GlobalAveragePooling2D()(out)\n",
    "out = tf.keras.layers.Dropout(0.2)(out)\n",
    "out = tf.keras.layers.Dense(4)(out)\n",
    "model = tf.keras.Model(inp, out)\n",
    "\n",
    "learning_rate = 0.0005\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "          loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "          metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "#preparing the weights for balanced training\n",
    "counts_mean = np.mean(tuple(data_train.counts.values()))\n",
    "class_weights = dict((k, counts_mean/v) for k,v in data_train.counts.items())\n",
    "print(f'class weights: {class_weights}')\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=0.00025, verbose = 1)\n",
    "\n",
    "checkpoint_folder = Path('checkpoints')\n",
    "checkpoint_folder.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "checkpoint_filepath = checkpoint_folder/f\"transfer_learning_classifier_n_{n_tiles}.h5\"\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model.fit(data_train.data.repeat(4),\n",
    "                epochs=40,\n",
    "                validation_data=data_val.data,\n",
    "                class_weight=class_weights, callbacks=[model_checkpoint_callback])\n",
    "np.save(checkpoint_folder/f\"transfer-learning_lr_{learning_rate:.4f}_epochs_{epochs}.npy\",history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history[f'sparse_categorical_accuracy']\n",
    "val_acc = history.history[f'val_sparse_categorical_accuracy']\n",
    "\n",
    "loss = history.history[f'loss']\n",
    "val_loss = history.history[f'val_loss']\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.title('Training and Validation Loss');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading weights from the best epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.keras.utils.image_dataset_from_directory('data/training/', shuffle=True, seed=1, validation_split=.1, subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = tuple(zip(*tuple(data.unbatch().as_numpy_iterator())))\n",
    "labels = tuple(np.array([l]) for l in labels)\n",
    "t = tf.data.Dataset.from_tensor_slices((images, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[0][None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array(data_val.labels)\n",
    "y_pred = np.argmax(model.predict(data_val.data), -1)\n",
    "\n",
    "def calculate_confusion_matrix(y_true, y_pred):\n",
    "    classes = tuple(data_val.class_id_to_name[i] for i in range(4))\n",
    "    matrix = metrics.confusion_matrix(y_true, y_pred) #rows - true, columns - predicted\n",
    "    matrix = matrix/np.sum(matrix, axis=-1, keepdims=True)\n",
    "    \n",
    "    df_cm = pd.DataFrame(matrix, index=classes, columns=classes)\n",
    "    # plt.figure(figsize=(10,7))\n",
    "    sns.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}, fmt='1.3f')# font size\n",
    "    plt.ylabel(\"True class\")\n",
    "    plt.xlabel(\"Predicted class\") \n",
    "    plt.show()\n",
    "    accuracy = np.sum(np.diag(matrix))/np.sum(matrix)\n",
    "    print(f'Accuracy: {accuracy:.4f}') \n",
    "    return accuracy\n",
    "\n",
    "accuracy = calculate_confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply the model to new images from a different microscope (`kings` subset)\n",
    "\n",
    "Put the `kings` images in the subfolder `data/kings`, resulting in \n",
    "\n",
    "```\n",
    "data\n",
    "├── fish_part_labels\n",
    "│   ├── DAPT\n",
    "│   ├── her1;her7\n",
    "│   ├── tbx6_fss\n",
    "│   └── WT\n",
    "├── kings\n",
    "│   ├── DAPT\n",
    "│   └── WT\n",
    "├── training\n",
    "│   ├── DAPT\n",
    "│   ├── her1;her7\n",
    "│   ├── tbx6_fss\n",
    "│   └── WT\n",
    "└── validation\n",
    "    ├── DAPT\n",
    "    ├── her1;her7\n",
    "    ├── tbx6_fss\n",
    "    └── WT\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = create_dataset(dataroot/'kings', augment=False, shuffle=False, target_size=target_size)\n",
    "\n",
    "x,y = next(iter(data_new.data))\n",
    "plt.figure(figsize=(20,5))\n",
    "for i, (_x, _y) in enumerate(zip(x[:2*n],y[:2*n])):\n",
    "    plt.subplot(2,n, i+1)\n",
    "    plt.imshow(np.clip(_x, 0,1))\n",
    "    plt.title(f'New image - class = {data_train.class_id_to_name[int(_y)]} ({int(_y)})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array(tuple(data_new.class_id_to_name[c] for c in data_new.labels))\n",
    "y_prob = tf.math.softmax(model.predict(data_new.data))\n",
    "y_pred = np.array(tuple(data_train.class_id_to_name[c] for c in np.argmax(y_prob, -1)))\n",
    "y_prob = np.max(y_prob, axis=-1)\n",
    "\n",
    "accuracy = np.mean(y_true==y_pred)\n",
    "print(f'Accuracy: {accuracy:.5f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, (x, fname, y1, y2, prob) in enumerate(zip(data_new.images, data_new.filenames, y_true, y_pred, y_prob)):\n",
    "    if i%4==0:\n",
    "        plt.figure(figsize=(20,4))\n",
    "    ax = plt.subplot(1,4,i%4+1)\n",
    "    ax.imshow(x)\n",
    "    correct = y1==y2\n",
    "    ax.set_title(f'{\"correct\" if correct else \"wrong\"} ({y1} -> {y2} with prob {prob:.2f})', fontsize=10)\n",
    "    ax.title.set_color('green' if correct else 'red')\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CAM analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#adapted from: https://nbviewer.jupyter.org/github/vincent1bt/Machine-learning-tutorials-notebooks/blob/master/activationMaps/ActivationsMaps.ipynb\n",
    "#deeper explanation here: https://vincentblog.xyz/posts/class-activation-maps\n",
    "def get_activation_map(image, image_class): \n",
    "        #we assume image is given in a shape of [0, a, b, 3] - axb RGB image in a tupple of 1 file - this is needed so that it's compatible with predict\n",
    "        #image_class is the true class\n",
    "\n",
    "        inp = tf.keras.Input(shape=target_size+(3,))\n",
    "        class_weights = model.layers[-1].get_weights()[0]\n",
    "        get_output = tf.keras.backend.function([inp], \n",
    "                                      [model_pretrained(inp)])\n",
    "        \n",
    "        predictions = model.predict(image, verbose=False)\n",
    "        [conv_outputs] = get_output(image)\n",
    "        conv_outputs = conv_outputs[0, :, :, :]\n",
    "\n",
    "        cam = np.zeros(dtype=np.float32, shape=conv_outputs.shape[0:2])\n",
    "\n",
    "        for index, weight in enumerate(class_weights[:, image_class]):\n",
    "            cam += weight * conv_outputs[:, :, index]\n",
    "        \n",
    "        class_predicted = np.argmax(predictions[0])\n",
    "        predictions = f'Class predicted: {class_predicted} | Real class: {image_class}'\n",
    "        \n",
    "        cam /= np.max(cam)\n",
    "        cam = resize(cam, (image.shape[1], image.shape[2]))\n",
    "        #puting cam into 0-1 range\n",
    "        scaled_cam = cam + np.abs(np.min(cam))\n",
    "        scaled_cam = scaled_cam/np.sum(scaled_cam) \n",
    "        return scaled_cam\n",
    "\n",
    "data_test = create_dataset(dataroot/\"validation\", target_size=target_size, batchsize=1, shuffle=False, augment=False, n_tiles=n_tiles)\n",
    "\n",
    "outfolder = Path('CAM_results')\n",
    "\n",
    "#saving of the predicted images\n",
    "cam_folders = dict((k, outfolder/v) for k,v in data_test.class_id_to_name.items())\n",
    "for k,folder in cam_folders.items():\n",
    "    folder.mkdir(exist_ok =True, parents=True)\n",
    "        \n",
    "#folder with parts of the fish\n",
    "folder_parts = dataroot/\"fish_part_labels\"\n",
    "\n",
    "for i, ((x,y),filename) in tqdm(enumerate(zip(data_test.data, data_test.filenames)), total=len(data_test.data)):\n",
    "    y_pred = np.argmax(model.predict(x,verbose=False), axis=-1)\n",
    "    y_true = int(y[0])\n",
    "    cam = get_activation_map(x, y_true)   \n",
    "    \n",
    "    fname_parts = Path(*Path(filename).parts[-2:])\n",
    "    parts = tifffile.imread(folder_parts/f'{fname_parts}.tiff')\n",
    "    resized_parts = resize(parts, (450,900), order=0) #everything is streched to the shape of the loaded image\n",
    "    parts_array_binarized = np.where(resized_parts > 0, 0, 1)\n",
    "\n",
    "    if i<10:\n",
    "        fig = plt.figure()\n",
    "        plt.imshow(x[0])   \n",
    "        plt.imshow(resize(cam,x[0].shape[:2]), alpha=0.4, cmap = 'magma')\n",
    "        plt.imshow(parts_array_binarized, alpha = 0.1)\n",
    "        plt.box(False)\n",
    "        plt.axis('off')\n",
    "    else:\n",
    "        break\n",
    "    plt.savefig(cam_folders[y_true]/Path(filename).name, dpi = fig.dpi, transparent=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the per-class- and per-fish-part CAM attention for images from the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_attention(image, mask, index, normalization = False):\n",
    "    if(image.shape != mask.shape):\n",
    "        raise Exception('Image and Mask should have the same shape', image.shape, mask.shape)\n",
    "\n",
    "    index_mask = (mask==index)\n",
    "    attention = np.sum(index_mask*image)\n",
    "    if normalization:\n",
    "        attention = attention / (np.sum(index_mask)+1e-10)\n",
    "    return attention\n",
    "\n",
    "Attention = np.empty((4, 6, 20)) #4 rows are the classes, 5 colums are different zebrafish parts\n",
    "#indices for zebrafish parts: (in the array as well the values on the zebrafish part paintings)\n",
    "#0 - background\n",
    "#1 - head\n",
    "#2 - trunk\n",
    "#3 - tail \n",
    "#4 - yolk\n",
    "#5 - yolk extension\n",
    "\n",
    "class_counter = np.zeros(4) #keeping track of how many images from a certain class there were so far\n",
    "normalization = 1\n",
    "\n",
    "for i, ((x,y),filename) in tqdm(enumerate(zip(data_test.data, data_test.filenames)), total=len(data_test.data)):\n",
    "    y_pred = np.argmax(model.predict(x,verbose=False), axis=-1)\n",
    "    y_true = int(y[0])\n",
    "    cam = get_activation_map(x, y_true)   \n",
    "    resized_cam = resize(cam, x[0].shape[:2])\n",
    "    #resizing changes values so we scale attention back to 1\n",
    "    resized_cam = resized_cam/np.sum(resized_cam)\n",
    "    \n",
    "    fname_parts = Path(*Path(filename).parts[-2:])\n",
    "    parts = tifffile.imread(folder_parts/f'{fname_parts}.tiff')\n",
    "    resized_parts = resize(parts, (450,900), order=0) #everything is streched to the shape of the loaded image\n",
    "\n",
    "    for p in range(0,6):\n",
    "        Attention[int(y_true), p, int(class_counter[int(y_true)])] = calculate_attention(resized_cam, resized_parts, p, normalization)                \n",
    "    class_counter[int(y_true)] = class_counter[int(y_true)] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting CAM results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plotting per class\n",
    "for i in range(4):\n",
    "    df = pd.DataFrame({'BKGD': Attention[i, 0, :], 'Head': Attention[i, 1, :], 'Trunk': Attention[i, 2, :], 'Tail': Attention[i, 3, :], 'Yolk': Attention[i, 4, :], 'Y.E.': Attention[i, 5, :]})\n",
    "    \n",
    "    plt.figure()\n",
    "    ax = sns.violinplot(data = df.iloc[:, 0:6]*100, color= np.array([185, 208, 229])/255, scale='width', bw = 'scott') #we scale Y axis so that it represents percentages\n",
    "    #ax.set(ylabel=\"Attention [%]\")\n",
    "    #plt.yticks([-1, 0, 1, 2, 3, 4, 5, 6])\n",
    "    plt.title(data_val.class_id_to_name[i])\n",
    "    plt.ylim([-0.0001, 0.0011])\n",
    "\n",
    "parts = ['BKGD', 'Head', 'Trunk', 'Tail', 'Yolk', 'Yolk Extension']\n",
    "\n",
    "#plotting per fish part\n",
    "for i in range(6):\n",
    "    df = pd.DataFrame({'WT': Attention[1, i, :], 'tbx6': Attention[3, i, :], 'DAPT': Attention[0, i, :], 'her1;her7': Attention[2, i, :]})\n",
    "    plt.figure()\n",
    "    ax = sns.violinplot(data = df.iloc[:, 0:6]*100, color= np.array([185, 208, 229])/255, scale='width', bw = 'scott') #we scale Y axis so that it represents percentages\n",
    "    #ax.set(ylabel=\"Attention [%]\")\n",
    "    #plt.yticks([-1, 0, 1, 2, 3, 4, 5, 6])\n",
    "    plt.title(parts[i])\n",
    "    plt.ylim([-0.0001, 0.0011])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data   = create_dataset(dataroot/\"validation\", target_size=target_size, batchsize=80, shuffle=True, augment=False, n_tiles=n_tiles)\n",
    "\n",
    "\n",
    "x,y = next(iter(data.data))\n",
    "plt.figure(figsize=(20,12))\n",
    "for i, (_x, _y) in enumerate(zip(x[:4*n],y[:4*n])):\n",
    "    plt.subplot(4,n, i+1)\n",
    "    plt.imshow(np.clip(_x, 0,1))\n",
    "    plt.title(f'Training - class = {data.class_id_to_name[int(_y)]} ({int(_y)})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
