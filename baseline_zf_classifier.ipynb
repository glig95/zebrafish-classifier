{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline classifier for zebrafish classification\n",
    "\n",
    "The baseline classifier is a shallow convolutional network which serves as a comparisson for the transfer learning classifier performance later on. The model contains 4 convolutional and maxpooling layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from skimage.transform import resize\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from itertools import islice\n",
    "from sklearn import metrics\n",
    "import glob\n",
    "import os\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.image as mpimg\n",
    "import shutil\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "import albumentations\n",
    "#check if GPU is visible\n",
    "#from tensorflow.python.client import device_lib\n",
    "#print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the zebrafish data\n",
    "\n",
    "Download and unzip the training data (images and classes) into the subfolder `data`\n",
    "```\n",
    "wget https://zenodo.org/record/6651752/files/data.zip?download=1  -O data.zip\n",
    "unzip data.zip\n",
    "```\n",
    "\n",
    "Which should result in the following \n",
    "\n",
    "```\n",
    "data\n",
    "├── fish_part_labels\n",
    "│   ├── DAPT\n",
    "│   ├── her1;her7\n",
    "│   ├── tbx6_fss\n",
    "│   └── WT\n",
    "├── training\n",
    "│   ├── DAPT\n",
    "│   ├── her1;her7\n",
    "│   ├── tbx6_fss\n",
    "│   └── WT\n",
    "└── validation\n",
    "    ├── DAPT\n",
    "    ├── her1;her7\n",
    "    ├── tbx6_fss\n",
    "    └── WT\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the zebrafish data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot= Path('data')\n",
    "target_size = (450,900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmentations \n",
    "\n",
    "transform = albumentations.Compose([\n",
    "    albumentations.HorizontalFlip(p=.5),\n",
    "    albumentations.VerticalFlip(p=.5),    \n",
    "    albumentations.GaussianBlur(p=.3),\n",
    "    albumentations.Affine(scale=(0.8,1.2), shear=0, rotate=(-10,10), cval=(1,1,1), p=.5),\n",
    "    albumentations.RandomBrightnessContrast(brightness_limit=.1, contrast_limit=.1, p=.5),\n",
    "    albumentations.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=.1, val_shift_limit=0, p=.5)\n",
    "])\n",
    "\n",
    "def preprocessing_function(x):\n",
    "    x = x/255\n",
    "    x = transform(image=x)['image']\n",
    "    return x\n",
    "\n",
    "path_train = dataroot/\"training\"\n",
    "path_val = dataroot/\"validation\"\n",
    "\n",
    "train_datagen_augmented = ImageDataGenerator(preprocessing_function=preprocessing_function)\n",
    "val_datagen = ImageDataGenerator( rescale = 1.0/255. ) \n",
    "\n",
    "data_train = train_datagen_augmented.flow_from_directory(path_train, batch_size = 16, class_mode = 'sparse', target_size = target_size)\n",
    "data_test = val_datagen.flow_from_directory(path_val,  batch_size = 16, class_mode = 'sparse', target_size = target_size)\n",
    "\n",
    "class_name_to_id = dict((k,v) for k,v in data_train.class_indices.items())\n",
    "class_id_to_name = dict((v,k) for k,v in data_train.class_indices.items())\n",
    "\n",
    "print(class_name_to_id)\n",
    "print(class_id_to_name)\n",
    "\n",
    "x,y = data_train.next()\n",
    "\n",
    "# lets plot some example augmented images \n",
    "w,h=5,3\n",
    "plt.figure(figsize=(20,10))\n",
    "for i, (_x, _y) in enumerate(zip(x[:w*h],y[:w*h])):\n",
    "    plt.subplot(h,w, i+1)\n",
    "    plt.imshow(np.clip(_x, 0,1))\n",
    "    c = int(_y)\n",
    "    plt.title(f'class = {class_id_to_name[c]} ({c})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building and compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(32,3,activation=\"relu\", padding=\"same\", input_shape = x.shape[1:]))\n",
    "model.add(tf.keras.layers.Conv2D(32,3,activation=\"relu\", padding=\"same\"))\n",
    "model.add(tf.keras.layers.MaxPooling2D((4,4)))\n",
    "model.add(tf.keras.layers.Conv2D(32,3,activation=\"relu\", padding=\"same\"))\n",
    "model.add(tf.keras.layers.Conv2D(32,3,activation=\"relu\", padding=\"same\"))\n",
    "model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(4,)) #from_logits = True so no need for softmax here\n",
    "\n",
    "model.summary()\n",
    "epochs = 200\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "          loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "          metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "#preparing the weights for balanced training\n",
    "counts = Counter(data_train.classes)\n",
    "counts_mean = np.mean(tuple(counts.values()))\n",
    "class_weights = dict((k, np.sqrt(counts_mean/v)) for k,v in counts.items())\n",
    "print(f'class weights: {class_weights}')\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,patience=2, min_lr=0.00025, verbose = 1)\n",
    "\n",
    "checkpoint_folder = Path('checkpoints')\n",
    "checkpoint_folder.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "checkpoint_filepath = checkpoint_folder/\"baseline_classifier.h5\"\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(data_train,\n",
    "                epochs=epochs,\n",
    "                validation_data = data_test,\n",
    "                class_weight=class_weights, callbacks=[model_checkpoint_callback])\n",
    "np.save(checkpoint_folder/f\"baseline_classifier_lr_{learning_rate:.4f}_epochs_{epochs}.npy\",history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading best weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = val_datagen.flow_from_directory(path_val,  batch_size = 16, class_mode = 'sparse', shuffle=False, target_size = target_size)\n",
    "\n",
    "y_true = data_test.classes\n",
    "y_pred = np.argmax(model.predict(data_test), -1)\n",
    "\n",
    "def calculate_confusion_matrix(y_true, y_pred):\n",
    "    classes = tuple(class_id_to_name[i] for i in range(4))\n",
    "    matrix = metrics.confusion_matrix(y_true, y_pred) #rows - true, columns - predicted\n",
    "    matrix = matrix/np.sum(matrix, axis=-1, keepdims=True)\n",
    "    \n",
    "    df_cm = pd.DataFrame(matrix, index=classes, columns=classes)\n",
    "    # plt.figure(figsize=(10,7))\n",
    "    sns.set(font_scale=1.4) # for label size\n",
    "    sns.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}, fmt='1.3f')# font size\n",
    "    plt.ylabel(\"True class\")\n",
    "    plt.xlabel(\"Predicted class\") \n",
    "    plt.show()\n",
    "    accuracy = np.sum(np.diag(matrix))/np.sum(matrix)\n",
    "    print(f'Accuracy: {accuracy:.4f}') \n",
    "    return accuracy\n",
    "\n",
    "accuracy = calculate_confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply the model to new images from a different microscope (`kings` subset)\n",
    "\n",
    "Put the `kings` images (in bmp format) in the subfolder `data/kings`, resulting in \n",
    "\n",
    "```\n",
    "data\n",
    "├── fish_part_labels\n",
    "│   ├── DAPT\n",
    "│   ├── her1;her7\n",
    "│   ├── tbx6_fss\n",
    "│   └── WT\n",
    "├── kings\n",
    "│   ├── DAPT\n",
    "│   └── WT\n",
    "├── training\n",
    "│   ├── DAPT\n",
    "│   ├── her1;her7\n",
    "│   ├── tbx6_fss\n",
    "│   └── WT\n",
    "└── validation\n",
    "    ├── DAPT\n",
    "    ├── her1;her7\n",
    "    ├── tbx6_fss\n",
    "    └── WT\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path_new = dataroot/'kings'\n",
    "save_folder = Path(\"test_predictions\") \n",
    "save_folder.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "new_datagen = ImageDataGenerator( rescale = 1.0/255. ) \n",
    "data_new = new_datagen.flow_from_directory(path_new,  batch_size = 1, shuffle=False, class_mode = 'sparse', target_size = target_size)\n",
    "class_id_to_name_test = dict((v,k) for k,v in data_new.class_indices.items())\n",
    "\n",
    "img = tuple(x for x, _ in islice(data_new, len(data_new)))\n",
    "y_true = np.array(tuple(class_id_to_name_test[c] for c in data_new.classes))\n",
    "y_pred = np.array(tuple(class_id_to_name[c] for c in np.argmax(model.predict(data_new), -1)))\n",
    "\n",
    "accuracy = np.mean(y_true==y_pred)\n",
    "print(f'Accuracy: {accuracy:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, (x, fname, y1, y2) in enumerate(zip(img, data_new.filenames, y_true, y_pred)):\n",
    "    plt.figure()\n",
    "    plt.imshow(x[0])\n",
    "    plt.title(f'{\"correct\" if y1==y2 else \"wrong\"} ({y1} -> {y2})', fontsize=10)\n",
    "    if(y1 == y2):\n",
    "        plt.savefig(save_folder/f'{Path(fname).name}_{y1}_correct_as_{y2}.jpg', dpi = 200, transparent=True)\n",
    "    else:\n",
    "        plt.savefig(save_folder/f'{Path(fname).name}_{y1}_wrong_as_{y2}.jpg', dpi = 200, transparent=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
